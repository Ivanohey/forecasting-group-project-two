# Data cleaning

```{r new_data}
#Flights from and to GVA airport daily
Airport_Traffic <- read_excel("data/Airport_Traffic.xlsx", sheet = "DATA")
Airport_Traffic = select(Airport_Traffic, FLT_DATE, APT_NAME, STATE_NAME, FLT_DEP_1, FLT_ARR_1) %>% rename(date = FLT_DATE, airport=APT_NAME, departures=FLT_DEP_1, arrivals=FLT_ARR_1)

#Selecting only swiss airports
Swiss_Traffic = Airport_Traffic[(Airport_Traffic$STATE_NAME=="Switzerland"),]


#####ONLY GENEVA TRAFFIC######
#Swiss_Traffic = Airport_Traffic[(Airport_Traffic$airport=="Geneva"),]

#Converting to dates
Swiss_Traffic = Swiss_Traffic %>% mutate(date = as.Date(date, format="%Y-%m-%d"))

duplicates(Swiss_Traffic)

#Adding up all the flights in the same day
Swiss_Traffic = Swiss_Traffic %>% aggregate(departures ~ date, sum)
head(Swiss_Traffic)

#Plotting our data
ggplot(Swiss_Traffic) + geom_line(aes(x=date,y=departures))

Swiss_Traffic$departures = na_ma(Swiss_Traffic$departures)
#Quite a lot of missing data
ggplot_na_distribution(Swiss_Traffic$departures)

```

```{r old_data}
# #Flights data
# data_2020 <- read.csv("data/2020-States.csv")
# data_2021 <- read.csv("data/2021-States.csv")
# data_2022 <- read.csv("data/2022-States.csv")
# data_2023 <- read.csv("data/2023-States.csv")
# 
# #Merge all flights datasets together
# data_2019 <- select(data_2020, Entity, Day.2019, Flights.2019..Reference.) %>% rename(Day = Day.2019, Flights = Flights.2019..Reference.)
# data_2020 <- select(data_2020, Entity, Day, Flights)
# data_2021 <- select(data_2021, Entity, Day, Flights)
# data_2022 <- select(data_2022, Entity, Day, Flights)
# data_2023 <- select(data_2023, Entity, Day, Flights)
# data_all_years <- rbind(data_2019, data_2020, data_2021, data_2022, data_2023)
# 
# #Select only data where country == switzerland
# flights <- data_all_years[data_all_years$Entity == 'Switzerland',]
# flights$year_month = format(as.Date(flights$Day), "%Y-%m")
# 
# flights <- flights %>% select(Day,Flights) %>% set_names(c("Date", "Flights"))
# 
# #Convert the "Date" column to a date format:
# #flights$Date <- parse_date_time(flights$Date, orders = c("%d-%b-%y", "%b %d, %Y"))
# flights <- flights %>% mutate(Date = as.Date(Date, format = "%Y-%m-%d"))
# 
# #This shows that date is correctly converted to date type
# str(flights)
# 
# #there are a bunch of duplicated rows, i guess because of the way the data was imported? 
# duplicates(flights)
# 
# #This will remove all the duplicated rows, and only keep one of them
# flights <- flights %>% 
#   distinct()
# 
# #now there's no more duplicates
# duplicates(flights)
# 

```

```{r holiday_data_scrapping}

# #Loading all the public holiday days
# page = read_html("https://www.officeholidays.com/countries/switzerland/2019");
# table_2019 = html_nodes(page, sprintf(".%s", "country-table")) %>% html_table()
# holidays_2019 = as.data.frame(table_2019) 
# holidays_2019$Date = paste0(holidays_2019$Date, " 2019")
# 
# page = read_html("https://www.officeholidays.com/countries/switzerland/2020");
# table_2020 = html_nodes(page, sprintf(".%s", "country-table")) %>% html_table()
# holidays_2020 = as.data.frame(table_2020)
# holidays_2020$Date = paste0(holidays_2020$Date, " 2020")
# 
# page = read_html("https://www.officeholidays.com/countries/switzerland/2021");
# table_2021 = html_nodes(page, sprintf(".%s", "country-table")) %>% html_table()
# holidays_2021 = as.data.frame(table_2021)
# holidays_2021$Date = paste0(holidays_2021$Date, " 2021")
# 
# page = read_html("https://www.officeholidays.com/countries/switzerland/2022");
# table_2022 = html_nodes(page, sprintf(".%s", "country-table")) %>% html_table()
# holidays_2022 = as.data.frame(table_2022)
# holidays_2022$Date = paste0(holidays_2022$Date, " 2022")
# 
# holidays_all_years = rbind(holidays_2019, holidays_2020, holidays_2021, holidays_2022)
# holidays_all_years = holidays_all_years[holidays_all_years$Type != "Not A Public Holiday", ]

#Scrapping the web pages containing the information for all seasons and cantons
page = read_html("https://www.holidays-info.com/switzerland/school-holidays/2015/")
school_2015 = html_nodes(page, "table") %>% html_table()
school_2015 = as.data.frame(school_2015) %>% filter(Var.1 == "Geneva" | Var.1 == "Vaud")# | Var.1 == "Valais" | Var.1 == "NeuchÃ¢tel")

page = read_html("https://www.holidays-info.com/switzerland/school-holidays/2016/")
school_2016 = html_nodes(page, "table") %>% html_table()
school_2016 = as.data.frame(school_2016) 

page = read_html("https://www.holidays-info.com/switzerland/school-holidays/2017/")
school_2017 = html_nodes(page, "table") %>% html_table()
school_2017 = as.data.frame(school_2017) 

page = read_html("https://www.holidays-info.com/switzerland/school-holidays/2018/")
school_2018 = html_nodes(page, "table") %>% html_table()
school_2018 = as.data.frame(school_2018) 

page = read_html("https://www.holidays-info.com/switzerland/school-holidays/2018/")
school_2018 = html_nodes(page, "table") %>% html_table()
school_2018 = as.data.frame(school_2018) 

page = read_html("https://www.holidays-info.com/switzerland/school-holidays/2019/")
school_2019 = html_nodes(page, "table") %>% html_table()
school_2019 = as.data.frame(school_2019) 

page = read_html("https://www.holidays-info.com/switzerland/school-holidays/2020/")
school_2020 = html_nodes(page, "table") %>% html_table()
school_2020 = as.data.frame(school_2020) 

page = read_html("https://www.holidays-info.com/switzerland/school-holidays/2021/")
school_2021 = html_nodes(page, "table") %>% html_table()
school_2021 = as.data.frame(school_2021) 

page = read_html("https://www.holidays-info.com/switzerland/school-holidays/2022/")
school_2022 = html_nodes(page, "table") %>% html_table()
school_2022 = as.data.frame(school_2022) 

#Creating dataset containing school holidays
start_date <- as.Date("2016-01-01")
end_date <- as.Date("2023-12-31")
dates <- seq(start_date, end_date, by = "day")
school_holidays_df <- data.frame(Date = dates, is_holiday = 0) #All rows are equal to 0

#Filling the rows where there are school holidays anywhere in switzerland
# creating list of strings:
extractValuesToList <- function(data) {
  valuesList <- list()  # Create an empty list to store the values
  
  # Iterate over each column
  for (col in 2:ncol(data)) {
    # Iterate over each row in the column
    for (row in 1:nrow(data)) {
      # Extract the value and add it to the list
      value <- data[row, col]
      valuesList <- append(valuesList, value)
    }
  }
  
  return(valuesList)  # Return the list of values
}

formatted_strings_2015 = extractValuesToList(school_2015)
formatted_strings_2016 = extractValuesToList(school_2016)
formatted_strings_2017 = extractValuesToList(school_2017)
formatted_strings_2018 = extractValuesToList(school_2018)
formatted_strings_2019 = extractValuesToList(school_2019)
formatted_strings_2020 = extractValuesToList(school_2020)
formatted_strings_2021 = extractValuesToList(school_2021)
formatted_strings_2022 = extractValuesToList(school_2022)


#Function to populate the main dataset
populate_data_holidays <- function(main_dataset, formatted_strings_year, current_year) {
  
  for (formatted_string in formatted_strings_year) {
  
  # Split the formatted string by "+" to separate the range and standalone days
  date_parts <- strsplit(formatted_string, " \\+ ")[[1]]
  range_parts <- list()
  standalone_parts <- list()
  
  #For each date parts, if the string is longer than 6 characters, define as range and append to list of ranges
  for (i in date_parts){
    if (nchar(i) > 6){
      #print(i)
      range_parts = append(range_parts, i)
    }
    else {
      standalone_parts = append(standalone_parts, i)
    }
  }
  
  for (i in range_parts){
    range_part <- i
    date_range <- unlist(strsplit(range_part, " - "))
   
    #If the date doesn't contain the year
    if (nchar(date_range[1]) <= 5) {
    start_range <- as.Date(paste(date_range[1], current_year), format = "%b %d , %Y")
    end_of_date_range = date_range[2]
    end_range <- as.Date(paste(date_range[2], current_year), format = "%b %d , %Y")
    
    # Update the "is_holiday" column for the range of dates
    school_holidays_df$is_holiday[school_holidays_df$Date >= start_range & school_holidays_df$Date <= end_range] <- 1
    } else {
    # Process the range part of the formatted string for dates with the year
    start_range_year <- as.Date(date_range[1], format = "%b %d , %Y")
    end_range_year <- as.Date(date_range[length(date_range)], format = "%b %d , %Y")
    # Update the "is_holiday" column for the range of dates
    school_holidays_df$is_holiday[school_holidays_df$Date >= start_range_year & school_holidays_df$Date <= end_range_year] <- 1
    }
  }
   for (i in standalone_parts) {
     if (nchar(i) > 1){
      standalone_part <- i
      print(standalone_part)
      standalone_days <- as.Date(paste(standalone_part, current_year), format = "%b %d , %Y")
      # Update the "is_holiday" column for the standalone days
      school_holidays_df$is_holiday[school_holidays_df$Date %in% standalone_days] <- 1
      standalone_days <- as.Date(paste(standalone_part, current_year), format = " %b %d , %Y")
      # Update the "is_holiday" column for the standalone days
      school_holidays_df$is_holiday[school_holidays_df$Date %in% standalone_days] <- 1
     }
   }
  }

  return(school_holidays_df)  
}

#Calling our function to populate our final dataset of holidays containing all holidays
school_holidays_df = populate_data_holidays(school_holidays, formatted_strings_2015, ", 2015")
school_holidays_df = populate_data_holidays(school_holidays, formatted_strings_2016, ", 2016")
school_holidays_df = populate_data_holidays(school_holidays, formatted_strings_2017, ", 2017")
school_holidays_df = populate_data_holidays(school_holidays, formatted_strings_2018, ", 2018")
school_holidays_df = populate_data_holidays(school_holidays, formatted_strings_2019, ", 2019")
school_holidays_df = populate_data_holidays(school_holidays, formatted_strings_2020, ", 2020")
school_holidays_df = populate_data_holidays(school_holidays, formatted_strings_2021, ", 2021")
school_holidays_df = populate_data_holidays(school_holidays, formatted_strings_2022, ", 2022")
school_holidays_df = school_holidays_df %>% rename(date = Date)

Swiss_F_H = left_join( x= Swiss_Traffic, y=school_holidays_df, by="date")

```



```{r gva_weather_data}
#Adding data for Swiss weather
Swiss_Weather = read_csv("./data/switzerland_weather2016-2023.csv") %>% select(datetime,temp, precip, snow, windspeed, humidity)
Swiss_Weather = rename(Swiss_Weather, date = datetime)

#Convert the "Date" column to a date format: (Previous type was POSIXct first time i'm seeing that)
#weather$Date <- parse_date_time(weather$Date, orders = c("%d-%b-%y", "%b %d, %Y"))
weather <- Swiss_Weather %>% mutate(Date = as.Date(date))

#Some summary statistics for all columns
str(weather)

#There are no duplicates here
duplicates(weather, index=date)

any(is.na(weather))

#visibility data for 2022-2023 looks very sus
ggplot(weather, aes(x = Date, y = windspeed)) +
  geom_line() +
  labs(title = "Wind speed over time", x = "Date", y = "Wind speed")

Swiss_F_H_W = left_join(Swiss_F_H, Swiss_Weather, by = "date") 

```

```{r oil_data}
#Oil data 

oil <- read.csv("data/BrentOilPrices.csv")

#Check for NA's, there's none
#sum(is.na(oil))

#Convert the "Date" column to a date format:
oil$Date <- parse_date_time(oil$Date, orders = c("%d-%b-%y", "%b %d, %Y"))

#Convert data to date type
oil <- oil %>% mutate(Date = as.Date(Date))

#check it's of the right type 
str(oil)

#Summary statistics 
oil %>% dfSummary(style = "grid")

#Plot the time series 
ggplot(oil, aes(x = Date, y = Price)) +
  geom_line() +
  labs(title = "Brent Oil Prices (all data)", x = "Date", y = "Price")

#convert to tsibble object -> NOT YET
#oil <- oil %>%
  #mutate(Date = yearmonth(Date)) %>% #need to do this before converting to get proper format
  #as_tsibble(index = Date)

#Select appropriate dates
oil <- oil %>%
  mutate(Date = as.Date(Date)) %>%
  filter(Date > as.Date("2019-01-01"))

#Plot the time series 
ggplot(oil, aes(x = Date, y = Price)) +
  geom_line() +
  labs(title = "Brent Oil Prices 2019 onwards", x = "Date", y = "Price")




#I do the following, becauase I realized that even though there are not explicit NA's, there are some date rows missing, and I need to create them... 


# create a complete sequence of dates from the minimum to maximum date
all_dates <- seq(min(oil$Date), max(oil$Date), by = "day")

# use complete() to create rows for the missing dates
oil <- oil %>% 
  complete(Date = all_dates)

# replace missing prices with NA
oil$Price[is.na(oil$Price)] <- NA

#There are 426 missing values now that I have completed the oil dataset... 
sum(is.na(oil))

#there are no duplicates here
duplicates(oil)

```

```{r}
#Trying with another oil dataset... THIS WAS EVEN WORSE

#newoil <- read.csv('data/crudeoil.csv')

#Converting date column to date type + format
#newoil <- newoil %>%
#  mutate(Date = as.Date(Date, format = "%m/%d/%Y"))

#Select relevant columns
#newoil <- newoil %>% select(Date,Close.Last)

#Select relevant dates
#newoil <- newoil %>%
#  mutate(Date = as.Date(Date)) %>%
#  filter(Date > as.Date("2019-01-01"))

#Plot the time series 
#ggplot(newoil, aes(x = Date, y = Close.Last)) +
#  geom_line() +
#  labs(title = "Oil Prices 2019 onwards", x = "Date", y = "Price")

#Check for NA's -> There are no NA's for the moment
#sum(is.na(newoil))


```


## Merging the datasets

```{r merging oil and old_flights data}
# #Merging datasets together 
# data <- flights %>%
#   #left_join(oil, by = "Date") %>%
#   left_join(weather, by = "Date")
# 
# data <- data %>% 
#   filter(Date < as.Date("2022-11-14"))
# 
# #Convert to tsibble object  
# ts_data <- data %>%
#   as_tsibble(index = Date)
# 
# 
# # #Plot the time series 
# # ts_data %>% autoplot(Price) +
# #   labs(title = "Brent Oil Prices 2019 onwards", x = "Date", y = "Price")
# 
# #Info on our variables
# str(ts_data)

```

As we can see there's a lot of missing values for the price variable. I will try to impute them using the KNN method: 

I discovered the imputeTS package, which includes various imputation methods, as well as some statistics for the missing values. Here are some of them: 

```{r}
library(imputeTS)

#No missing data in the full dataset
ggplot_na_distribution(Swiss_F_H_W$is_holiday)
ggplot_na_distribution(Swiss_F_H_W$windspeed)
ggplot_na_distribution(Swiss_F_H_W$departures)
ggplot_na_distribution(Swiss_F_H_W$temp)
ggplot_na_distribution(Swiss_F_H_W$humidity)


# #missing data statistics -> actually quite useful to see what's going on
# statsNA(ts_data$Price)
# 
# #I'm choosingthe moving average method to impute the data.
# ts_data$Price <- na_ma(ts_data$Price)
# 
# #Plot the time series
# ts_data %>% autoplot(Price) +
#   labs(title = "Brent Oil Prices 2019 onwards - IMPUTED", x = "Date", y = "Price")

```
In the imputeTS package, there are a lot of methods to impute the data, and after trying some we decided to stick with the weighted moving average. This is because most frequently (185 times) the gap is only 2 NA values long. There are 13 cases where the gap is 3 NA's long, and only 4 cases where the gap is 4 NA's long. This means that using the weighted moving average is providing a very good approximation of the price data. 

If the gaps were longer and the NA's were all concentrated in one big area, then we would consider using other imputation methods, but this is really not the case. The missing values seem to be spread all over the data, so the moving weighted averate seems to be doing a great job. 

Finally, let's check to see if there's any missing data after imputation

```{r}
# #Final check
# any(is.na(ts_data)) #seems there are still some NA's
# 
# # Identify rows with missing values
# na_rows <- !complete.cases(ts_data)
# 
# # Print rows with missing values
# ts_data[na_rows,]

```
It looks like there are 6 rows with missing values in the visibility column. I will just use the same same function as previously to impute them. 

```{r}
# #I'm choosing the moving average method to impute the data.
# ts_data$visibility <- na_ma(ts_data$visibility)
# 
# any(is.na(ts_data))
```

Finally, I need to round the values to 2 decimals for Price and visibility

```{r}
# # ts_data$Price <- round(ts_data$Price, 2)
# ts_data$visibility <- round(ts_data$visibility, 2)
```

